{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader,Dataset,Subset\n",
    "from importlib import import_module\n",
    "from IPython.display import display\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything,LightningDataModule,loggers,seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from torchmetrics.functional import accuracy\n",
    "from dataclasses import dataclass,asdict\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.contrib import tzip,tenumerate\n",
    "from omegaconf import OmegaConf\n",
    "from collections import *\n",
    "seed_everything(42)\n",
    "\n",
    "dataset_dir=\"/home/lvhang/autodl-tmp/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "channel_stats = dict(mean = [0.4914, 0.4822, 0.4465],\n",
    "                            std = [0.2023, 0.1994, 0.2010])\n",
    "eval_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(**channel_stats)\n",
    "        ])\n",
    "data=tv.datasets.CIFAR10(root=dataset_dir, train=True, download=True,transform=eval_transform)\n",
    "a,b= DataLoader([],100),range(20)\n",
    "for q,w in zip(a,b):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_split_subset(dataset,indice,length,shuffle=False):\n",
    "    full_targets,indices=np.array(dataset.targets),np.array(indice)\n",
    "    sub_targets=full_targets[indices]\n",
    "    unique_labels=np.unique(sub_targets)\n",
    "    subsets=[]\n",
    "    used_label_num=defaultdict(int)\n",
    "    for ratio in length:\n",
    "        # for every item in length, construct a subset\n",
    "        indice=[]\n",
    "        for y in unique_labels:\n",
    "            indice_idxes=np.where(sub_targets==y)[0]\n",
    "            targets_idxes=indices[indice_idxes]\n",
    "            cur=int(ratio*len(indice_idxes))\n",
    "            used=used_label_num[y]\n",
    "            indice.extend(targets_idxes[used:used+cur])\n",
    "            used_label_num[y]+=cur\n",
    "        if shuffle: np.random.shuffle(indice)\n",
    "        subsets.append(Subset(dataset, indice))\n",
    "    return subsets\n",
    "\n",
    "def uniform_split_dataset(dataset,length,shuffle=True):\n",
    "    targets=np.array(dataset.targets)\n",
    "    subsets,unique_labels,used_label_num=[],np.unique(targets),defaultdict(int)\n",
    "    for ratio in length:\n",
    "        # for every item in length, construct a subset\n",
    "        indice=[]\n",
    "        for y in unique_labels:\n",
    "            # for every label, append ratio*len idxes into indice\n",
    "            idxes=np.where(targets==y)[0]\n",
    "            cur=int(ratio*len(idxes))\n",
    "            used=used_label_num[y]\n",
    "            indice.extend(idxes[used:used+cur])\n",
    "            used_label_num[y]+=cur\n",
    "        if shuffle: np.random.shuffle(indice)\n",
    "        subsets.append(Subset(dataset, indice))\n",
    "    return subsets\n",
    "\n",
    "def uniform_split(dataset,length,shuffle=False):\n",
    "    if len(dataset)==0: \n",
    "        return [[]]*len(length)\n",
    "    if isinstance(dataset,Subset):\n",
    "        # if is subset, restore subset to full-dataset while keep indice stay subset\n",
    "        indice=np.array(dataset.indices)\n",
    "        while isinstance(dataset,Subset):\n",
    "            dataset=dataset.dataset\n",
    "        return uniform_split_subset(dataset,indice,length,shuffle)\n",
    "    else:\n",
    "        return uniform_split_dataset(dataset,length,shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=uniform_split(tv.datasets.CIFAR10(root=dataset_dir, train=True, download=True,transform=eval_transform),[1,0])\n",
    "len(a),len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m],\u001b[39m4\u001b[39;49m,replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32mmtrand.pyx:965\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "np.random.choice([1,2,3],4,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 10])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c=torch.rand((100,10)),torch.rand((50,10)),torch.rand((60,10))\n",
    "d=torch.cat((a,b,c))\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,w,e=d.chunk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "    \n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.out_channels, \n",
    "            kernel_size=self.kernel_size, \n",
    "            stride=self.stride, \n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "        \n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        net = x\n",
    "        \n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "        \n",
    "        net = self.max_pool(net)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "                \n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "        \n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "            \n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "        \n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "        \n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "        \n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "                \n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "            \n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=self.kernel_size, \n",
    "                stride = self.stride, \n",
    "                groups = self.groups, \n",
    "                downsample=downsample, \n",
    "                use_bn = self.use_bn, \n",
    "                use_do = self.use_do, \n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x.view([x.shape[0], 1, -1]).float()\n",
    "        \n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "        \n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet1D(\n",
    "    in_channels=1, \n",
    "    base_filters=128, # 64 for ResNet1D, 352 for ResNeXt1D\n",
    "    kernel_size=16, \n",
    "    stride=2, \n",
    "    groups=32, \n",
    "    n_block=48, \n",
    "    n_classes=10, \n",
    "    downsample_gap=6, \n",
    "    increasefilter_gap=12, \n",
    "    use_do=True)\n",
    "\n",
    "data=torch.rand((10,228))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0932e-01,  1.1567e-01,  6.6576e-01,  3.0436e-01, -3.4896e-01,\n",
       "          1.9701e-01, -5.3079e-02,  1.4760e-01,  2.3587e-02, -2.3489e-01],\n",
       "        [ 6.5987e-01,  3.4905e-01,  4.3179e-01, -3.5097e-01,  5.2153e-01,\n",
       "         -2.0827e-01, -4.6656e-01, -4.2674e-01, -6.1366e-01,  3.0319e-01],\n",
       "        [ 2.7515e-01, -1.9486e-01,  3.1357e-01,  5.3429e-01, -3.2544e-01,\n",
       "         -5.2247e-01, -2.0388e-01, -7.0947e-01, -2.3968e-01,  2.7082e-01],\n",
       "        [ 1.1587e+00,  2.4648e-01,  9.3658e-01,  3.1973e-01,  1.2939e-01,\n",
       "          8.6242e-01, -8.4129e-02, -1.7655e-01, -1.0802e+00, -3.0260e-02],\n",
       "        [-7.2247e-04,  1.6144e-01,  4.1531e-01, -1.5344e-01, -3.9538e-01,\n",
       "         -7.1296e-01, -4.2701e-01, -1.8378e-01,  3.7335e-02,  2.9495e-01],\n",
       "        [ 7.7061e-01, -3.6196e-01,  4.5273e-02,  2.9359e-02, -5.1546e-02,\n",
       "         -2.3553e-01, -1.2109e-01, -2.0411e-01,  9.2551e-02,  6.0740e-01],\n",
       "        [ 6.2648e-02,  2.4502e-01,  5.2747e-03,  2.1646e-01,  2.3483e-01,\n",
       "          1.1304e-01, -6.6548e-02, -2.3245e-01, -4.5845e-01, -3.6522e-01],\n",
       "        [ 7.2000e-02,  2.9436e-01,  5.0362e-02,  4.7823e-01, -2.1385e-01,\n",
       "         -2.4590e-01, -3.0250e-02,  1.3611e-01,  9.8709e-02,  1.2696e-01],\n",
       "        [-1.3602e-01,  6.8969e-01, -9.1678e-02,  2.1275e-01,  6.3585e-02,\n",
       "         -3.8571e-01,  1.2974e-01,  1.0920e-01,  3.1291e-01,  7.9218e-02],\n",
       "        [ 8.1678e-01,  1.1645e-01,  1.6031e+00,  3.0207e-01, -7.3529e-01,\n",
       "         -3.4594e-01, -5.7275e-01, -3.0035e-01, -4.6528e-01,  6.9293e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84273b81cdc42a3264e484c6789250ffbb1f676ed6cfb3490cefbba355fcc21f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
